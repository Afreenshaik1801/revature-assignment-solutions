{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d4bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Extracting data from CSV...\n",
      "‚úÖ Data extracted. Sample:\n",
      "   Customer_Id     Customer_Name           Customer_Location  Order_ID  \\\n",
      "0           10     Mary Vega DDS         China, Beijing Shi       2268   \n",
      "1           20     Brandon Myers  193, Bannerghatta Main Rd       3082   \n",
      "2           30    Margaret Wells            Behrenstra√üe 42       3160   \n",
      "3           40  Michael Matthews            Behrenstra√üe 42       1272   \n",
      "4           50   Connor Williams  Floreasca Park 43 Soseaua       9447   \n",
      "\n",
      "   Order_Quantity  Order_Price  \n",
      "0               5        16.52  \n",
      "1               4        17.27  \n",
      "2               1         3.37  \n",
      "3               5         2.20  \n",
      "4               1        12.23  \n",
      "üîÑ Transforming data...\n",
      "‚úÖ Transformation complete. Sample:\n",
      "   Customer_Id     Customer_Name           Customer_Location  Order_ID  \\\n",
      "0           10     Mary Vega DDS         China, Beijing Shi       2268   \n",
      "1           20     Brandon Myers  193, Bannerghatta Main Rd       3082   \n",
      "2           30    Margaret Wells            Behrenstra√üe 42       3160   \n",
      "3           40  Michael Matthews            Behrenstra√üe 42       1272   \n",
      "4           50   Connor Williams  Floreasca Park 43 Soseaua       9447   \n",
      "\n",
      "   Order_Quantity  Order_Price             load_timestamp  \n",
      "0               5        16.52 2025-10-30 15:03:05.792853  \n",
      "1               4        17.27 2025-10-30 15:03:05.792853  \n",
      "2               1         3.37 2025-10-30 15:03:05.792853  \n",
      "3               5         2.20 2025-10-30 15:03:05.792853  \n",
      "4               1        12.23 2025-10-30 15:03:05.792853  \n",
      "‚ÑπÔ∏è Dataset 'BigQuery_ETL_Assignment' already exists.\n",
      "‚ÑπÔ∏è Table 'Customer_Orders' already exists.\n",
      "üöÄ Loading transformed data into BigQuery...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded 50 rows into trim-plexus-396409.BigQuery_ETL_Assignment.Customer_Orders.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.api_core.exceptions import Conflict\n",
    "\n",
    "PROJECT_ID = \"trim-plexus-396409\"\n",
    "DATASET_ID = \"BigQuery_ETL_Assignment\"\n",
    "TABLE_ID = \"Customer_Orders\"\n",
    "CSV_PATH = r\"E:\\BigQueryAssignment\\Customer_Orders.csv\"\n",
    "\n",
    "key_path = r\"E:\\BigQueryAssignment\\trim-plexus-396409-dfc55c39f51e.json\" \n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "\n",
    "print(\"Extracting data from CSV...\")\n",
    "df = pd.read_csv(CSV_PATH, encoding=\"ISO-8859-1\")\n",
    "\n",
    "print(\"Data extracted. Sample:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"Transforming data...\")\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "df[\"Order_Price\"] = df[\"Order_Price\"].fillna(df[\"Order_Price\"].mean())\n",
    "\n",
    "from datetime import datetime\n",
    "df[\"load_timestamp\"] = datetime.now()\n",
    "\n",
    "print(\"Transformation complete. Sample:\")\n",
    "print(df.head())\n",
    "\n",
    "dataset_ref = bigquery.Dataset(f\"{PROJECT_ID}.{DATASET_ID}\")\n",
    "\n",
    "try:\n",
    "    client.create_dataset(dataset_ref)\n",
    "    print(f\"Dataset '{DATASET_ID}' created.\")\n",
    "except Conflict:\n",
    "    print(f\"Dataset '{DATASET_ID}' already exists.\")\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"Customer_Id\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"Customer_Name\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Customer_Location\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"Order_ID\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"Order_Quantity\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"Order_Price\", \"FLOAT\"),\n",
    "]\n",
    "\n",
    "table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
    "table = bigquery.Table(table_ref, schema=schema)\n",
    "\n",
    "try:\n",
    "    client.create_table(table)\n",
    "    print(f\"Table '{TABLE_ID}' created.\")\n",
    "except Conflict:\n",
    "    print(f\"Table '{TABLE_ID}' already exists.\")\n",
    "\n",
    "print(\"Loading transformed data into BigQuery...\")\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=\"WRITE_APPEND\", \n",
    "    schema_update_options=[\n",
    "        bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION,\n",
    "    ]\n",
    ")\n",
    "\n",
    "job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
    "job.result()\n",
    "\n",
    "print(f\"Successfully loaded {len(df)} rows into {table_ref}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
